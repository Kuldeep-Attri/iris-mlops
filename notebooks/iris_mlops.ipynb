{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Package"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.simplefilter('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import pickle\n",
    "from pathlib import Path\n",
    "from itertools import product\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import mlflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR = \"/Users/kuldeepsharma/github/mlops/iris-mlops/data/\"\n",
    "RAW_DATA_PATH = DATA_DIR + \"raw_data.csv\"\n",
    "PROCESSED_DATA_PATH = DATA_DIR + \"processed_data.csv\"\n",
    "MODEL_PATH = \"/Users/kuldeepsharma/github/mlops/iris-mlops/models/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extract Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SepalLengthCm</th>\n",
       "      <th>SepalWidthCm</th>\n",
       "      <th>PetalLengthCm</th>\n",
       "      <th>PetalWidthCm</th>\n",
       "      <th>Species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>52</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>Iris-versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116</td>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>Iris-virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>23</td>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Id  SepalLengthCm  SepalWidthCm  PetalLengthCm  PetalWidthCm  \\\n",
       "0   52            6.4           3.2            4.5           1.5   \n",
       "1  116            6.4           3.2            5.3           2.3   \n",
       "2   23            4.6           3.6            1.0           0.2   \n",
       "\n",
       "           Species  \n",
       "0  Iris-versicolor  \n",
       "1   Iris-virginica  \n",
       "2      Iris-setosa  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(RAW_DATA_PATH)\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transform Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_lenght</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_lenght</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>4.5</td>\n",
       "      <td>1.5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.4</td>\n",
       "      <td>3.2</td>\n",
       "      <td>5.3</td>\n",
       "      <td>2.3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_lenght  sepal_width  petal_lenght  petal_width  target\n",
       "0           6.4          3.2           4.5          1.5       1\n",
       "1           6.4          3.2           5.3          2.3       2\n",
       "2           4.6          3.6           1.0          0.2       0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Remove 'Id' Column\n",
    "data = data.drop(columns=['Id'], axis=1)\n",
    "\n",
    "### Rename Columns\n",
    "data.columns = [\"sepal_lenght\", \"sepal_width\", \"petal_lenght\",\n",
    "                    \"petal_width\", \"target\"]\n",
    "\n",
    "### Encode Labels\n",
    "data[\"target\"] = data[\"target\"].map(\n",
    "        {\"Iris-setosa\": 0, \"Iris-versicolor\": 1, \"Iris-virginica\": 2}\n",
    "    )\n",
    "\n",
    "### Drop Duplicates\n",
    "data = data.drop_duplicates()\n",
    "\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv(PROCESSED_DATA_PATH, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prepara Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Split data in train, val and test\n",
    "X = data.drop(columns=['target']).values\n",
    "y = data['target'].values\n",
    "\n",
    "X_train, X_temp, y_train, y_temp =\\\n",
    "    train_test_split(X, y, test_size=0.3, stratify=y, random_state=3)\n",
    "X_val, X_test, y_val, y_test =\\\n",
    "    train_test_split(X_temp, y_temp, test_size=0.5, stratify=y_temp, random_state=3)\n",
    "\n",
    "### Convert to tensors\n",
    "X_train = torch.FloatTensor(X_train)\n",
    "X_val = torch.FloatTensor(X_val)\n",
    "X_test = torch.FloatTensor(X_test)\n",
    "y_train = torch.LongTensor(y_train)\n",
    "y_val = torch.LongTensor(y_val)\n",
    "y_test = torch.LongTensor(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model & Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNeuralNetwork(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim,\n",
    "            layer1_dim=128, layer2_dim=64, act=\"relu\"):\n",
    "        \n",
    "        super(SimpleNeuralNetwork,self).__init__()\n",
    "        self.input_layer    = nn.Linear(input_dim, layer1_dim)\n",
    "        self.hidden_layer1  = nn.Linear(layer1_dim, layer2_dim)\n",
    "        self.output_layer   = nn.Linear(layer2_dim, output_dim)\n",
    "        if act == \"relu\":\n",
    "            self.act = nn.ReLU()\n",
    "        if act == \"tanh\":\n",
    "            self.act = nn.Tanh()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x =  self.act(self.input_layer(x))\n",
    "        x =  self.act(self.hidden_layer1(x))\n",
    "        x =  self.output_layer(x)\n",
    "        return x\n",
    "    \n",
    "\n",
    "### Parameters\n",
    "num_epochs = 100\n",
    "input_dim  = 4 \n",
    "output_dim = 3\n",
    "model = SimpleNeuralNetwork(input_dim, output_dim, \n",
    "            layer1_dim=128, layer2_dim=64, act=\"relu\")\n",
    "\n",
    "# Creating our optimizer and loss function\n",
    "learning_rate = 0.01\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train & Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/100\n",
      "Train Loss: 0.3722\n",
      "Train Accuracy: 0.8675\n",
      "Val Loss: 0.3059\n",
      "Val Accuracy: 0.9444\n",
      "Epoch 20/100\n",
      "Train Loss: 0.1353\n",
      "Train Accuracy: 0.9639\n",
      "Val Loss: 0.0781\n",
      "Val Accuracy: 1.0000\n",
      "Epoch 30/100\n",
      "Train Loss: 0.0616\n",
      "Train Accuracy: 0.9759\n",
      "Val Loss: 0.0262\n",
      "Val Accuracy: 1.0000\n",
      "Epoch 40/100\n",
      "Train Loss: 0.0414\n",
      "Train Accuracy: 0.9880\n",
      "Val Loss: 0.0224\n",
      "Val Accuracy: 1.0000\n",
      "Epoch 50/100\n",
      "Train Loss: 0.0336\n",
      "Train Accuracy: 0.9880\n",
      "Val Loss: 0.0143\n",
      "Val Accuracy: 1.0000\n",
      "Epoch 60/100\n",
      "Train Loss: 0.0287\n",
      "Train Accuracy: 0.9759\n",
      "Val Loss: 0.0108\n",
      "Val Accuracy: 1.0000\n",
      "Epoch 70/100\n",
      "Train Loss: 0.0256\n",
      "Train Accuracy: 1.0000\n",
      "Val Loss: 0.0079\n",
      "Val Accuracy: 1.0000\n",
      "Epoch 80/100\n",
      "Train Loss: 0.0234\n",
      "Train Accuracy: 1.0000\n",
      "Val Loss: 0.0072\n",
      "Val Accuracy: 1.0000\n",
      "Epoch 90/100\n",
      "Train Loss: 0.0214\n",
      "Train Accuracy: 1.0000\n",
      "Val Loss: 0.0051\n",
      "Val Accuracy: 1.0000\n",
      "Epoch 100/100\n",
      "Train Loss: 0.0244\n",
      "Train Accuracy: 1.0000\n",
      "Val Loss: 0.0010\n",
      "Val Accuracy: 1.0000\n"
     ]
    }
   ],
   "source": [
    "def train_n_validate_model(model, optimizer, criterion,\n",
    "    X_train, y_train, X_val, y_val, num_epochs):\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_train = model(X_train)\n",
    "        loss_train = criterion(output_train, y_train)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train = loss_train.item()\n",
    "        _, predicted_train = torch.max(output_train, 1)\n",
    "        correct_predictions_train = (predicted_train == y_train).sum().item()\n",
    "        total_train_samples = y_train.size(0) * 1.0\n",
    "        \n",
    "        model.eval()\n",
    "        output_val = model(X_val)\n",
    "        loss_val = criterion(output_val, y_val)\n",
    "        _, predicted_val = torch.max(output_val, 1)\n",
    "        correct_predictions_val = (predicted_val == y_val).sum().item()\n",
    "        total_val_samples = y_val.size(0) * 1.0\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f\"Epoch {epoch+1}/{num_epochs}\")\n",
    "            print(f\"Train Loss: {loss_train:.4f}\")\n",
    "            print(f\"Train Accuracy: {correct_predictions_train/total_train_samples:.4f}\")\n",
    "            print(f\"Val Loss: {loss_val:.4f}\")\n",
    "            print(f\"Val Accuracy: {correct_predictions_val/total_val_samples:.4f}\")\n",
    "\n",
    "train_n_validate_model(model, optimizer, criterion, X_train, y_train, X_val, y_val, num_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.44 %\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "94.44"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def test_model(model, X_test, y_test):\n",
    "    \n",
    "    model.eval()\n",
    "\n",
    "    output_test = model(X_test)\n",
    "    _, predicted_test = torch.max(output_test, 1)\n",
    "    correct_predictions_test = (predicted_test == y_test).sum().item()\n",
    "    total_test_samples = y_test.size(0) * 1.0\n",
    "    accuracy = round(correct_predictions_test / total_test_samples, 4)\n",
    "    print(f\"Test Accuracy: {accuracy * 100.0} %\")\n",
    "    return accuracy * 100.0\n",
    "\n",
    "test_model(model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiments Tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Config MLflow\n",
    "MODEL_REGISTRY = Path(\"/tmp/mlflow\")\n",
    "Path(MODEL_REGISTRY).mkdir(parents=True, exist_ok=True)\n",
    "MLFLOW_TRACKING_URI = \"file://\" + str(MODEL_REGISTRY.absolute())\n",
    "mlflow.set_tracking_uri(MLFLOW_TRACKING_URI)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///tmp/mlflow/589294911647954324', creation_time=1691308017249, experiment_id='589294911647954324', last_update_time=1691308017249, lifecycle_stage='active', name='iris-notebook-experiments', tags={}>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create or get an experiment\n",
    "experiment_name = \"iris-notebook-experiments\"\n",
    "mlflow.set_experiment(experiment_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_n_validate_model_mlflow(model, optimizer, criterion,\n",
    "    X_train, y_train, X_val, y_val, num_epochs, train_losses, val_losses):\n",
    "\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        output_train = model(X_train)\n",
    "        loss_train = criterion(output_train, y_train)\n",
    "        loss_train.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        loss_train = loss_train.item()\n",
    "        train_losses[epoch] = loss_train\n",
    "        \n",
    "        model.eval()\n",
    "        output_val = model(X_val)\n",
    "        loss_val = criterion(output_val, y_val)\n",
    "\n",
    "        loss_val = loss_val.item()\n",
    "        val_losses[epoch] = loss_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 88.89 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 88.89 %\n",
      "Test Accuracy: 88.89 %\n",
      "Test Accuracy: 88.89 %\n",
      "Test Accuracy: 83.33 %\n",
      "Test Accuracy: 66.67 %\n",
      "Test Accuracy: 66.67 %\n",
      "Test Accuracy: 33.33 %\n",
      "Test Accuracy: 88.89 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 88.89 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 88.89 %\n",
      "Test Accuracy: 88.89 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 66.67 %\n",
      "Test Accuracy: 83.33 %\n",
      "Test Accuracy: 100.0 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 66.67 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 33.33 %\n",
      "Test Accuracy: 100.0 %\n",
      "Test Accuracy: 100.0 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 100.0 %\n",
      "Test Accuracy: 100.0 %\n",
      "Test Accuracy: 100.0 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n",
      "Test Accuracy: 94.44 %\n"
     ]
    }
   ],
   "source": [
    "### Parameters\n",
    "input_dim  = 4 \n",
    "output_dim = 3\n",
    "\n",
    "num_epochs = [10, 50, 100]\n",
    "learning_rates = [0.1, 0.01]\n",
    "layer1_dims = [64, 128, 256]\n",
    "layer2_dims = [32, 64, 128]\n",
    "activation_functions = [\"relu\"]\n",
    "\n",
    "combinations = product(num_epochs, learning_rates,\n",
    "                    layer1_dims, layer2_dims, activation_functions)\n",
    "\n",
    "for i, combination in enumerate(combinations):\n",
    "    num_epochs, lr, l1_dim, l2_dim, act = combination\n",
    "\n",
    "    model = SimpleNeuralNetwork(input_dim=input_dim, output_dim=output_dim,\n",
    "                                layer1_dim=l1_dim, layer2_dim=l2_dim, act=act)\n",
    "\n",
    "\n",
    "    learning_rate = lr\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    train_losses = np.zeros(num_epochs)\n",
    "    val_losses = np.zeros(num_epochs)\n",
    "\n",
    "    train_n_validate_model_mlflow(model, optimizer, criterion,\n",
    "        X_train, y_train, X_val, y_val, num_epochs, train_losses, val_losses)\n",
    "\n",
    "    with mlflow.start_run(run_name=f\"run-1.{i}\", description=f\"version-1\") as run:\n",
    "        params = {\n",
    "            \"input_dim\": input_dim,\n",
    "            \"output_dim\": output_dim,\n",
    "            \"num_epochs\": num_epochs,\n",
    "            \"learning_rate\": learning_rate,\n",
    "            \"layer1_dim\": l1_dim,\n",
    "            \"layer2_dim\": l2_dim,\n",
    "            \"activation_function\": act,\n",
    "        }\n",
    "        mlflow.log_params(params=params)\n",
    "\n",
    "        mlflow.pytorch.log_model(model, f\"iris-pytorch-model\")\n",
    "\n",
    "        for i in range(len(list(train_losses))):\n",
    "            mlflow.log_metrics({\"train_loss\": list(train_losses)[i]}, step=i)\n",
    "            mlflow.log_metrics({\"val_loss\": list(val_losses)[i]}, step=i)\n",
    "\n",
    "        accuracy = test_model(model, X_test, y_test)\n",
    "        mlflow.log_metrics({\"accuracy\": accuracy})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 94.44 %\n"
     ]
    }
   ],
   "source": [
    "# Search for runs in the experiment, ordered by validation loss\n",
    "sorted_runs = mlflow.search_runs(experiment_names=[experiment_name],\n",
    "                                    order_by=[\"metrics.val_loss ASC\"])\n",
    "if not sorted_runs.empty:\n",
    "    best_run_id = sorted_runs.iloc[0].run_id\n",
    "    # Load the best model using the artifact URI\n",
    "    best_model = mlflow.pytorch.load_model(f\"runs:/{best_run_id}/iris-pytorch-model\")\n",
    "\n",
    "    # Now you can use the best_model for inference or evaluation\n",
    "    accuracy = test_model(best_model, X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please go to mlflow ui and cretae a production model registry manually :(\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"./../src\")\n",
    "\n",
    "from utils import mlflow_config\n",
    "\n",
    "mlflow = mlflow_config()\n",
    "\n",
    "try:\n",
    "    production_model_run_id = mlflow.models.get_model_info(\n",
    "                f\"models:/iris-production-model/Production\"\n",
    "            ).run_id\n",
    "except:\n",
    "    print(\"Please go to mlflow ui and cretae a production model registry manually :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlops",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
